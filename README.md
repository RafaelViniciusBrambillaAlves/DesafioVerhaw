# DesafioVerhaw


Este projeto tem como objetivo a extra√ß√£o automatizada de dados do Portal da Transpar√™ncia do Governo Brasileiro, organiza√ß√£o desses dados em arquivos CSV, processamento das informa√ß√µes relevantes e envio para uma API. O processo √© orquestrado utilizando o Apache Airflow para garantir a execu√ß√£o automatizada das tarefas.

## Desafio

Este projeto foi desenvolvido como parte de um desafio t√©cnico para uma vaga. 

## Tecnologias Utilizadas üî®

- **Python**: Linguagem principal para scripts de extra√ß√£o, transforma√ß√£o e envio de dados. 
- **Selenium**: Biblioteca para automa√ß√£o de navegador utilizada na extra√ß√£o dos dados.
- **Pandas**: Para processamento e transforma√ß√£o de dados.
- **Apache Airflow**: Ferramenta de orquestra√ß√£o de workflows utilizada para agendar e gerenciar tarefas.
- **Docker**: Cont√™ineriza√ß√£o do ambiente para facilitar a execu√ß√£o e replica√ß√£o do projeto.
- **PostgreSQL**: Banco de dados utilizado pelo Airflow.

## Estrutura do Projeto üìö

### 1. Arquivos de Configura√ß√£o

- **docker-compose.yml**: Define os servi√ßos utilizados no projeto, como o Airflow, PostgreSQL, Selenium e os volumes compartilhados. Configura a comunica√ß√£o entre os diferentes cont√™ineres.
- **Dockerfile**: Extende a imagem base do Apache Airflow e instala as depend√™ncias listadas em `requirements.txt`.
- **requirements.txt**: Lista as bibliotecas Python necess√°rias, como Selenium.

### 2. Scripts de Extra√ß√£o e Processamento

- **web_scraper.py**: Script respons√°vel por automatizar a navega√ß√£o no Portal da Transpar√™ncia e baixar o arquivo CSV de receitas. Utiliza o Selenium para controlar o navegador Chrome.
- **organize.py**: Ap√≥s o download, este script organiza e renomeia o arquivo CSV baixado com a data atual, garantindo que os arquivos sejam identificados corretamente.
- **data_processor.py**: Carrega o arquivo CSV organizado, filtra as colunas relevantes e transforma os dados em um dicion√°rio pronto para ser enviado.
- **send_to_api.py**: Cont√©m a fun√ß√£o para enviar os dados processados para uma API externa. Envia os dados no formato JSON utilizando uma requisi√ß√£o HTTP POST.

### 3. DAG do Airflow

- **receitas_etl_dag.py**: Define a DAG (Directed Acyclic Graph) do Airflow que orquestra todo o processo ETL. As tarefas incluem o download dos dados, organiza√ß√£o dos arquivos, processamento das informa√ß√µes e envio para a API.
  - **Tarefa `download_receitas`**: Executa o script de extra√ß√£o.
  - **Tarefa `organize_files`**: Organiza o arquivo baixado.
  - **Tarefa `process_send_data`**: Processa os dados e envia para a API.

## Instru√ß√µes de Uso üèÉ

### 1. Clonar o Reposit√≥rio

Clone o reposit√≥rio em sua m√°quina local:

```bash
git clone https://github.com/RafaelViniciusBrambillaAlves/DesafioVerhaw.git
cd DesafioVerhaw
```

### 2. Configurar e Executar os Cont√™ineres

Construa e inicie os servi√ßos Docker definidos no docker-compose.yml:

```bash
docker-compose up --build
```

Isso ir√° iniciar os servi√ßos do Airflow, PostgreSQL, Selenium, e o restante do ambiente necess√°rio.

### 3. Acessar o Airflow

Acesse o Airflow Web UI atrav√©s do navegador:

```
http://localhost:8080
```

Logue-se com as credenciais configuradas (usu√°rio: airflow, senha: airflow).

### 4. Executar a DAG

No Airflow, ative a DAG receitas_dag e execute-a manualmente ou aguarde o agendamento di√°rio.

### 5. Verificar os Resultados

Os arquivos CSV processados ser√£o armazenados na pasta csv do cont√™iner, e os dados processados ser√£o enviados para a API especificada.

## Considera√ß√µes Finais

Este projeto demonstra a capacidade de automatizar um fluxo de trabalho complexo utilizando tecnologias modernas de orquestra√ß√£o e cont√™ineriza√ß√£o. As habilidades t√©cnicas aplicadas incluem automa√ß√£o de navega√ß√£o web, manipula√ß√£o e transforma√ß√£o de dados, integra√ß√£o com APIs e orquestra√ß√£o de tarefas em ambientes de cont√™iner.
___

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)

